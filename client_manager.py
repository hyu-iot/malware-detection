import numpy as np
import torch
from torch.utils.data import TensorDataset, DataLoader

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

class ClientManager():

  def __init__(self, config):
    self.config = config
    self.trainloaders = []
    self.testloaders = []

  def build_dataset(self, DATA_PATH, config=None):

    if config:
      self.config = config
    
    self.orig_data = np.load(DATA_PATH, allow_pickle=True)
    scaler = MinMaxScaler()
    scaler.fit(self.orig_data[:, 1:])
    dataset = self.orig_data
    dataset[:, 1:] = scaler.transform(self.orig_data[:, 1:])

    if self.config["type"].lower() == "lstm":
      trainsets, testsets = self.__build_lstm_dataset(dataset, self.config)
    elif self.config["type"].lower() == "dnn":
      trainsets, testsets = self.__build_nn_dataset(dataset, self.config)

    return trainsets, testsets
  
  def build_dataloader(self, DATA_PATH, config=None):    

    if config:
      self.config = config

    trainloaders, testloaders = [], []
    trainsets, testsets = self.build_dataset(DATA_PATH, self.config)
    for ds_train, ds_test in zip(trainsets, testsets):
      if ds_train is None:
        trainloaders.append(None)
        testloaders.append(None)
        continue

      trainloaders.append(DataLoader(ds_train, batch_size=self.config["batch_size"], shuffle=self.config["shuffle"]))
      testloaders.append(DataLoader(ds_test, batch_size=self.config["batch_size"], shuffle=self.config["shuffle"]))
  
    self.trainloaders = trainloaders
    self.testloaders = testloaders

    return trainloaders, testloaders


  def get_dataloader(self, index):
    if index >= len(self.trainloaders) or index < 0:
      return None, None
    else:
      return self.trainloaders[index], self.testloaders[index]


  def __build_lstm_dataset(self, dataset, config):
    
    data, lengths = self.__split_timestamp(dataset, config["period"])
    trainsets, testsets = [], []

    for d, len in zip(data, lengths):

      if len == 0:
        trainsets.append(None)
        testsets.append(None)
        continue

      train_len = int(config["train_ratio"] * len)      
      test_len = len - train_len
      train_data, test_data = d[:train_len], d[train_len:]
      X_train, y_train = self.__manipulate_sequence(train_data, config["seq_len"])
      X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)
      trainsets.append(TensorDataset(X_train, y_train))
      
      X_test, y_test = self.__manipulate_sequence(test_data, config["seq_len"])
      X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test)
      testsets.append(TensorDataset(X_test, y_test))
      
    return trainsets, testsets
  

  def __build_nn_dataset(self, dataset, config):
    
    data, lengths = self.__split_timestamp(dataset, config["period"])
    trainsets, testsets = [], []

    for d, len in zip(data, lengths):
      if len < 2:
        trainsets.append(None)
        testsets.append(None)
        continue

      X_train, X_test, y_train, y_test = train_test_split(d[:, :-12], d[:, -12:], train_size=config["train_ratio"], random_state=config["random_seed"])
      X_train, X_test, y_train, y_test = torch.from_numpy(X_train).float(), torch.from_numpy(X_test).float(), torch.from_numpy(y_train), torch.from_numpy(y_test)

      trainsets.append(TensorDataset(X_train, y_train))
      testsets.append(TensorDataset(X_test, y_test))

    return trainsets, testsets
    
  def __split_timestamp(self, data, period):
    results, lengths = [], []
    start_time, end_time = data[0][0], data[-1][0]
    counts = int(np.ceil((end_time-start_time) / float(period)))

    for c in range(counts):
      tmp = np.array([data[i][1:] for i in range(data.shape[0]) if data[i][0] >= start_time + c*period and data[i][0] <= start_time + (c+1)*period])
      results.append(tmp)
      lengths.append(len(tmp))
      
    return results, lengths

  def __manipulate_sequence(self, data, seq_len):
    X = []
    y = []
    for i in range(0, len(data)-seq_len):
      X.append(data[i:i+seq_len, :-12])
      y.append(data[i+seq_len, -12:])
    
    return np.array(X), np.array(y)
