import flwr as fl
import pandas as pd
import numpy as np
import torch
from torch.utils.data import DataLoader, ConcatDataset, TensorDataset
from torchmetrics import F1Score
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import f1_score, precision_score, recall_score

from collections import OrderedDict
from typing import List, Dict, Tuple, Optional
import os
import json
from tqdm import tqdm

from client import FLClient
from client_manager import ClientManager
from model import Net, LSTMNet
from utils import get_parameters, set_parameters, train, test, plot_metrics


conn_state_dict = {
    'S0': 0,
    'S1': 1,
    'S2': 2,
    'S3': 3,
    'SF': 4,
    'SH': 5,
    'SHR': 6,
    'REJ': 7,
    'RSTO': 8,
    'RSTR': 9,
    'RSTOS0': 10,
    'RSTRH': 11,
    'OTH': 12,
}

proto_dict = {
    'tcp': 0,
    'udp': 1,
    'icmp': 2,
}

service_dict = {
    ' ': 0,
    'http': 1,
    'dhcp': 2,
    'ssh': 3,
    'dns': 4,
    'irc': 5,
    'ssl': 6,
}

replace_dicts = {
    "proto": proto_dict,
    "service": service_dict,
    "conn-state": conn_state_dict,
}

# all_labels = ['Attack', 'Benign', 'C&C', 'C&C-FileDownload', 'C&C-HeartBeat', 
#           'C&C-HeartBeat-Attack', 'C&C-HeartBeat-FileDownload', 'C&C-Mirai', 
#           'C&C-PartOfAHorizontalPortScan', 'C&C-Torii', 'DDoS', 'FileDownload', 
#           'Okiru', 'PartOfAHorizontalPortScan', 'PartOfAHorizontalPortScan-Attack']

all_labels = ['Benign', 'Malicious']          


def convert_history_to_numeric(history):
  if history == ' ':
    return 0
  
  if isinstance(history, int):
    return history

  letters = ['s', 'h', 'a', 'd', 'f', 'r', 'c', 'g', 't', 'w', 'i', 'q', '^',
             'S', 'H', 'A', 'D', 'F', 'R', 'C', 'G', 'T', 'W', 'I', 'Q']
  
  history_dict = dict(zip(letters, range(1, len(letters)+1)))
  result = 1

  for i, c in enumerate(history):
    if i >= 5:  break
    result = result * len(history) + history_dict[c]

  return result


DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
EPOCH = 2
NUM_CLIENTS = 10

learning_rate = 0.01
global_round = 1

# devices = [1, 3, 7, 8, 9, 17, 20, 21, 33, 34,
#            35, 36, 39, 42, 43, 44, 48, 49, 52, 60]

#devices = [3, 8, 9, 20, 21, 34, 42, 44, 48, 60]           

devices = [3, 7, 8, 9, 20, 21, 34, 35, 48, 60]
val_devices = [1, 17, 33, 36, 39, 42, 43, 44, 49, 52]
num_min_samples_ratio = 0.2

cfg = {
    'device': 1,
    'unit_period': 60,
    'period': 1800,
    'DIR_PATH': "",
    'train_ratio': 0.7,
    'random_seed': 1234,
    'batch_size': 20,
    'shuffle': True,
    'reliability': 0.9,
}



cms = {}

for device in devices:
  config = cfg.copy()
  config['device'] = device
  config['DIR_PATH'] = f"./dataset/{device}"
  cms[device] = ClientManager(config)


#df_val = pd.read_csv(f"./dataset/validation_data.csv")
df_val = pd.read_csv(f"./dataset/validation_binary.csv")
df_val = df_val.drop(columns=['ts', 'id.orig_h', 'id.resp_h'])
df_val = df_val.replace(replace_dicts)
df_val.history = df_val.history.apply(convert_history_to_numeric)

label_columns = ['label_' + label for label in all_labels]

df_current_labels = pd.get_dummies(df_val, columns=['label'])
df_labels = pd.DataFrame(columns=label_columns)

for label in label_columns:
  if label in df_current_labels.columns.values:
    df_labels[label] = df_current_labels[label].copy()

df_labels = df_labels.fillna(0)
print(f"Label counts for validation data: {df_val.label.value_counts()}")
df_val = df_val.drop(columns=['label'])  

df_val = df_val.astype(float)
df_labels = df_labels.astype(int)

scaler = MinMaxScaler()
scaler.fit(df_val)
df_val = pd.DataFrame(scaler.transform(df_val), columns=df_val.columns)

X_val, y_val = torch.tensor(df_val.values), torch.tensor(df_labels.values)

valset = TensorDataset(X_val, y_val)

valloader = DataLoader(
    valset,
    batch_size=cfg['batch_size'],
    shuffle=cfg['shuffle'],
)

print(f"Length of validation Dataset: {len(valset)}\n\
        Length of validation Dataloader: {len(valloader)}")

# valset = ConcatDataset([cm.round(0).get_dataset()[0] for cm in cms.values()])
# valloader = DataLoader(
#     valset,
#     batch_size=cfg['batch_size'],
#     shuffle=cfg['shuffle'],
# )


def client_fn(cid: str) -> FLClient:
  """ Create a Flower client representing a single organization. """
  
  # Get ClientManager
  cm = cms[devices[int(cid)]]
  
  # Load model
  net = Net().to(DEVICE)

  # Load data
  trainloader, testloader = cm.round(global_round).get_dataloader()

  # Create a single Flower client representing a single organization
  return FLClient(net, trainloader, testloader, DEVICE)


# Server-side
fedavg_losses, fedavgM_losses, qfedavg_losses = [], [], []
fedavg_accuracies, fedavgM_accuracies, fedavg_accuracies = [], [], []

# The `evaluate` function will be by Flower called after every round
def evaluate(
    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]
) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:
    global global_round

    net = Net()

    set_parameters(net, parameters)  # Update model with the latest parameters
    loss, accuracy, pred, target = test(net, valloader, DEVICE)
    
    global_round += 1

    average = 'micro'
    recall = recall_score(pred, target, average=average)
    precision = precision_score(pred, target, average=average)
    f1 = f1_score(pred, target, average=average)

    #print(f"Pred: {pred}\tTarget: {target}")

    # f1 = F1Score(task="multiclass", num_classes=14)
    # f1_score = f1(pred, target).item()

    # fedavg_losses.append(loss)
    # fedavg_accuracies.append(accuracy)

    print(f"Server-side evaluation loss {loss} / accuracy {accuracy} / recall: {recall} / precision: {precision} / f1: {f1}")
    return loss, {"loss": loss, "accuracy": accuracy, "recall": recall, "precision": precision, "f1_score": f1}


def fit_config (global_round: int):
    #Return training configuration dict for each round
    config = {
        "global_round": global_round,
    }
    return config

def evaluate_config (global_round: int):
    config = {
        "global_round": global_round,
    }
    return config



# Define strategies
fedavg = fl.server.strategy.FedAvg(
    fraction_fit=1.0,             # Sample 100% of available clients for training
    fraction_evaluate=0.5,        # Sample 50% of available clients for evaluation
    min_fit_clients=10,           # Never sample less than 10 clients for training
    min_evaluate_clients=5,       # Never sample less than 5 clients for evaluation
    min_available_clients=10,     # Wait until all 10 clients are available
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

fedavgM = fl.server.strategy.FedAvgM(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

qfedavg = fl.server.strategy.QFedAvg(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

ftfedavg = fl.server.strategy.FaultTolerantFedAvg(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

fedopt = fl.server.strategy.FedOpt(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

fedadagrad = fl.server.strategy.FedAdagrad(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

fedadam = fl.server.strategy.FedAdam(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

fedyogi = fl.server.strategy.FedYogi(
    fraction_fit=1.0,             
    fraction_evaluate=0.5,        
    min_fit_clients=10,           
    min_evaluate_clients=5,       
    min_available_clients=10,
    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),
    evaluate_fn=evaluate,
    on_fit_config_fn=fit_config,
    on_evaluate_config_fn=evaluate_config,
)

results = {}
#strategies = [fedavg, fedavgM, qfedavg, ftfedavg, fedopt, fedadam, fedadagrad, fedyogi]
#strategies = [fedavg, fedopt, fedadam, fedadagrad, fedyogi]
strategies = [fedavg, fedavgM, ftfedavg, fedopt, fedadam, fedadagrad, fedyogi]



# Start simulation
for strategy in strategies:
    global_round = 1

    net = Net().to(DEVICE)
    hist = fl.simulation.start_simulation(
        client_fn=client_fn,
        num_clients=NUM_CLIENTS,
        config=fl.server.ServerConfig(num_rounds=40),
        strategy=strategy
    )
    results[repr(strategy).split('(')[0]] = hist.metrics_centralized


with open(f"./results/result.json", mode="w") as result_file:
    json.dump(results, result_file)

plot_metrics("./results/result.json")
