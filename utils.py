import numpy as np
import torch

import json
from collections import OrderedDict
from typing import List

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator


def get_parameters(net) -> List[np.ndarray]:
    return [val.cpu().numpy() for _, val in net.state_dict().items()]

def set_parameters(net, parameters: List[np.ndarray]):
    params_dict = zip(net.state_dict().keys(), parameters)
    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})
    net.load_state_dict(state_dict, strict=True)

def train(net, train_loader, epochs, DEVICE):
  """ Train the network on the training set. """
  criterion = torch.nn.CrossEntropyLoss()
  optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)

  avg_cost = 0.0

  for i in range(epochs):
    avg_cost = 0.0
    total_batch = len(train_loader)

    for X, y in train_loader:
      net.train()
      X, y = X.to(DEVICE), y.to(DEVICE)
      optimizer.zero_grad()

      loss = criterion(net(X), y.double())
      loss.backward()
      optimizer.step()

      avg_cost += loss.item() / total_batch

  return avg_cost


def test(net, test_loader, DEVICE):
  """ Evaluate the network on the entire test set. """
  criterion = torch.nn.CrossEntropyLoss()
  correct, total, loss = 0, 0, 0.0

  pred = torch.Tensor([])
  target = torch.Tensor([])
  net.eval()

  with torch.no_grad():
    for X, y in test_loader:
        net.eval()
        X, y = X.to(DEVICE), y.to(DEVICE)
        outputs = net(X)

        _, predicted = torch.max(outputs.data, 1)
        loss += criterion(outputs, y.double()).item()
        correct += (predicted == y.argmax(-1)).sum().item()
        pred = torch.cat([pred, predicted], dim=0)
        target = torch.cat([target, y.argmax(-1)], dim=0)
        total += y.size(0)

    loss /= len(test_loader.dataset)
    accuracy = correct / total

    return loss, accuracy, pred, target



def plot_metrics(RESULT_PATH):
    with open(RESULT_PATH) as result_file:
      results = json.load(result_file)

    for metric in ["loss", "accuracy", "f1_score"]:
      fig, ax = plt.subplots()

      for strategy, result in results.items():
        xs = [item[0] for item in result[metric]]
        ys = [item[1] for item in result[metric]]
        ax.plot(xs, ys, label=strategy)

      ax.legend()
      ax.xaxis.set_major_locator(MaxNLocator(integer=True))

      plt.xlabel("Round")
      plt.ylabel(metric.capitalize())
      plt.title(f"Evaluation about {metric}")
      plt.savefig(f"./results/Evaluate_{metric}.png")
      plt.clf()


if __name__ == "__main__":
  plot_metrics("./results/result.json")