import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator

import torch
from torch.utils.data import TensorDataset, DataLoader, random_split
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from typing import List, Tuple, Optional, Dict

import json
import itertools

DATA_X = "./dataset/iot23_X.npy"
DATA_Y = "./dataset/iot23_Y.npy"

BATCH_SIZE = 100
NUM_CLIENTS = 10

def load_data():
  X = np.load(DATA_X)
  y = np.load(DATA_Y)

  scaler = MinMaxScaler()
  scaler.fit(X)
  X = scaler.transform(X)

  scaler.fit(y)
  y = scaler.transform(y)

  X = torch.from_numpy(X)
  y = torch.from_numpy(y)


  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)

  trainset = TensorDataset(X_train, y_train)
  testset = TensorDataset(X_test, y_test)

  # Split training data into 10 partitions to simulate the individual dataset
  partition_size = len(trainset) // NUM_CLIENTS
  lengths = [partition_size] * NUM_CLIENTS
  lengths[-1] += len(trainset) % NUM_CLIENTS
  print(lengths)
  datasets = random_split(trainset, lengths, torch.Generator().manual_seed(1234))
  

  # Split each partition into train/val and create DataLoader
  trainloaders = []
  valloaders = []
  for ds in datasets:
    len_val = len(ds) // 10  # 10% validation set
    len_train = len(ds) - len_val
    lengths = [len_train, len_val]
    ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(1234))
    trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))
    valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))
  testloader = DataLoader(testset, batch_size=BATCH_SIZE)

  return trainloaders, valloaders, testloader


def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        #cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm = torch.div(cm, torch.sum(cm, 1).view(-1, 1))

        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()



def plot_metrics(RESULT_PATH):
    with open(RESULT_PATH) as result_file:
      results = json.load(result_file)

    for metric in ["loss", "accuracy", "f1_score"]:
      fig, ax = plt.subplots()

      for strategy, result in results.items():
        xs = [item[0] for item in result[metric]]
        ys = [item[1] for item in result[metric]]
        ax.plot(xs, ys, label=strategy)

      ax.legend()
      ax.xaxis.set_major_locator(MaxNLocator(integer=True))

      plt.xlabel("Round")
      plt.ylabel(metric.capitalize())
      plt.title(f"Evaluation about {metric}")
      plt.savefig(f"./results/Evaluate_{metric}.png")
      plt.clf()


if __name__ == "__main__":
  plot_metrics("./results/result.json")