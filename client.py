from collections import OrderedDict

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import TensorDataset, DataLoader
from torchvision.datasets import CIFAR10
from sklearn.model_selection import train_test_split

import flwr as fl

from model import Net

BATCH_SIZE=100
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def load_data():

    X = np.load("./dataset/iot23_X.npy")
    y = np.load("./dataset/iot23_Y.npy")

    X = torch.from_numpy(X)
    y = torch.from_numpy(y)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)

    train_data = TensorDataset(X_train, y_train)
    test_data = TensorDataset(X_test, y_test)

    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)

    num_examples = {"trainset" : len(train_data), "testset": len(test_data)}

    return train_loader, test_loader, num_examples


def train(net, train_loader, epochs):
    """Train the network on the training set."""
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
    
    
    for epoch in range(epochs):
        avg_cost = 0.0
        total_batch = len(train_loader)

        for X, y in train_loader:
            X, y = X.to(DEVICE), y.to(DEVICE)
            optimizer.zero_grad()
            loss = criterion(net(X), y)
            loss.backward()
            optimizer.step()

            avg_cost += loss / total_batch

        print(f"Epoch: {epoch + 1}, Cost: {avg_cost}")



def test(net, test_loader):
    "Validate the network on the entire test set."
    criterion = torch.nn.CrossEntropyLoss()
    correct, total, loss = 0, 0, 0.0
    with torch.no_grad():
        for X, y in test_loader:
            X, y = X.to(DEVICE), y.to(DEVICE)
            outputs = net(X)
            loss += criterion
            _, predicted = torch.max(outputs.data, 1)
            total += y.size(0)
            correct += (predicted == y).sum().item()
    
    accuracy = correct / total
    return loss, accuracy

class FLClient(fl.client.NumPyClient):
    def __init__(self, net, train_loader, test_loader):
        self.net = net
        self.train_loader = train_loader
        self.test_loader = test_loader


    def get_parameters(self, config):
        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]
    
    def set_parameters(self, parameters):
        params_dict = zip(self.net.state_dict().keys(), parameters)
        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})
        self.net.load_state_dict(state_dict, strict=True)

    def fit(self, parameters, config):
        self.set_parameters(parameters)
        train(self.net, self.train_loader, epochs=5)
    
    def evaluate(self, parameters, config):
        self.set_parameters(parameters)
        loss, accuracy = test(self.net, self.test_loader)
        return loss, len(self.test_loader.dataset), {"accuracy": accuracy}


if __name__ == "__main__":
    
    net = Net().to(DEVICE)
    train_loader, test_loader, num_examples = load_data()

    train(net, train_loader, 10)

    # fl.client.start_numpy_client(
    #     server_address="127.0.0.1:3000",
    #     client=FLClient(net, train_loader, test_loader),
    # )
